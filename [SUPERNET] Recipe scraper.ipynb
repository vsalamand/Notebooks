{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "511d554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining functions to scrape website & food blogs\n",
    "## 1. With application/ld+json\n",
    "## 2. With schema tags itemprop\n",
    "## 3. With unstructured format \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cffba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_ld= [\n",
    "    \"https://www.marmiton.org/recettes/recette_gratin-dauphinois-tres-facile_58956.aspx\",\n",
    "    \"https://clemfoodie.com/2021/08/22/crumble-aux-prunes-rouges-et-amandes/\",\n",
    "    \"https://tangerinezest.com/pizza-tomate-burrata-basilic-et-mortadelle/\",\n",
    "    \"https://recettesdejulie.fr/10351/crumble-mirabelles-avoine-noisettes/\"\n",
    "]\n",
    "    \n",
    "microdata = [\n",
    "    \"https://mesbrouillonsdecuisine.fr/pancakes-sales-a-la-farine-de-pois-chiches-jeunes-pousses-depinards-et-tomates-sechees/\"\n",
    "]\n",
    "    \n",
    "hard_test_urls = [\n",
    "    \"https://www.undejeunerdesoleil.com/2018/05/tramezzini-thon-artichauts-venise.html\",\n",
    "    \"http://www.chezmisa.com/burgers-de-boeuf-persilles-et-sauce-au-miel/\",\n",
    "    \"https://cookingjulia.blogspot.com/2021/08/poulet-la-mexicaine.html\",\n",
    "    \"https://wernerhappyeats.com/djeunerdner/2017/12/29/grilled-chicken-lunch-bento-yxbn2\",\n",
    "    \"https://doriannn.blogspot.com/2021/08/knackinkorea-parce-que-decidement-je-ne.html\",\n",
    "    \"https://madamcadamia.com/2021/09/02/crumble-aux-mures-et-noisettes/\",\n",
    "    \"https://www.plusunemiettedanslassiette.fr/moules-marinara/\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "966b3d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import extruct\n",
    "import pprint\n",
    "from w3lib.html import get_base_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83879091",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe = scrape_recipe(hard_test_urls[1])\n",
    "recipe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a380d2",
   "metadata": {},
   "source": [
    "# Scrapping class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "39d3a071",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scrape_recipe(url):\n",
    "    recipe = scrape_structured_data(url)\n",
    "    if recipe is None:\n",
    "        recipe = scrape_unstructured_data(url)\n",
    "    return recipe\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943d3f52",
   "metadata": {},
   "source": [
    "# 0. Ingredients filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "88fc2ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "saved_model_path = \"/Users/vincentsalamand/Documents/datascience/models/recipe_cat_spacy_model_150921_full\"\n",
    "nlp = spacy.load(saved_model_path)\n",
    "\n",
    "def get_ingredients(text_list):\n",
    "    docs = list(nlp.pipe(text_list))\n",
    "    predictions = []\n",
    "    for doc in docs:\n",
    "        if max(doc.cats, key=doc.cats.get) == \"ingredient\":\n",
    "            predictions.append(doc.text)\n",
    "    return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc30ed18",
   "metadata": {},
   "source": [
    "# 1. Scrapping JSON-LD OR MICRODATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "90ae70dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Fetch structured JSON-LD OR MICRODATA data from a given URL.\"\"\"\n",
    "from typing import Optional, List\n",
    "import requests\n",
    "import extruct\n",
    "from w3lib.html import get_base_url\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_structured_data(url: str) -> Optional[List[dict]]:\n",
    "    \"\"\"Parse structured data from a URL.\"\"\"\n",
    "    headers = {\n",
    "        'Access-Control-Allow-Origin': '*',\n",
    "        'Access-Control-Allow-Methods': 'GET',\n",
    "        'Access-Control-Allow-Headers': 'Content-Type',\n",
    "        'Access-Control-Max-Age': '3600',\n",
    "        'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0'\n",
    "    }    \n",
    "    req = requests.get(url, headers=headers)\n",
    "    base_url = get_base_url(req.content, url)\n",
    "    html = get_html(url) \n",
    "    metadata = get_metadata(html, url)\n",
    "    try:\n",
    "        if metadata:\n",
    "            recipe_df = get_recipe_df(metadata)\n",
    "            recipe = {\"recipe\": {\n",
    "                         \"name\": recipe_df.name.values[0],\n",
    "                         \"yield\": recipe_df.recipeYield.values[0],\n",
    "                         \"ingredients\": get_ingredients(recipe_df.recipeIngredient.values[0])\n",
    "                        }\n",
    "                    }            \n",
    "            return recipe\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_html(url: str):\n",
    "    \"\"\"Get raw HTML from a URL.\"\"\"\n",
    "    headers = {\n",
    "        'Access-Control-Allow-Origin': '*',\n",
    "        'Access-Control-Allow-Methods': 'GET',\n",
    "        'Access-Control-Allow-Headers': 'Content-Type',\n",
    "        'Access-Control-Max-Age': '3600',\n",
    "        'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0'\n",
    "    }\n",
    "    req = requests.get(url, headers=headers)\n",
    "    return req.text\n",
    "\n",
    "\n",
    "def get_metadata(html, url: str):\n",
    "    r = requests.get(url)\n",
    "    \"\"\"Fetch JSON-LD structured data.\"\"\"\n",
    "    metadata = extruct.extract(\n",
    "        html,\n",
    "        base_url = get_base_url(r.text, r.url),\n",
    "        syntaxes=['json-ld'],\n",
    "        uniform=True\n",
    "    )['json-ld']\n",
    "    \"\"\"If empty, try fetch Microdata structured data.\"\"\"    \n",
    "    if metadata == []:\n",
    "        metadata = extruct.extract(\n",
    "            html,\n",
    "            base_url = get_base_url(r.text, r.url),\n",
    "            syntaxes=['microdata'],\n",
    "            uniform=True\n",
    "        )['microdata']        \n",
    "    if bool(metadata) and isinstance(metadata, list):\n",
    "        metadata = metadata[0]\n",
    "    return metadata\n",
    "\n",
    "def get_recipe_df(metadata):\n",
    "    #check metadata dict format \n",
    "    if '@graph' in metadata:\n",
    "        recipe_df = pd.DataFrame(metadata['@graph'])\n",
    "    else:\n",
    "        recipe_df = pd.DataFrame.from_dict(metadata, orient='index').transpose()\n",
    "    #get first row with recipeIngredient\n",
    "    recipe_df = recipe_df.sort_values(by='recipeIngredient').head(1)\n",
    "    return recipe_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c68bc24",
   "metadata": {},
   "source": [
    "# 2. Non-structured data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620b0ab5",
   "metadata": {},
   "source": [
    "## Using spaCy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b29d6eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trafilatura import fetch_url, extract\n",
    "import trafilatura\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "\n",
    "def scrape_unstructured_data(url: str):\n",
    "    downloaded = fetch_url(url)\n",
    "    # to get the main text of a page\n",
    "    if downloaded is not None:\n",
    "        result = extract(downloaded, include_comments=False)\n",
    "        text = sentence_parser(result)\n",
    "        if text is not None:\n",
    "            df = pd.DataFrame(text, columns=['text']).dropna()\n",
    "            recipe = {\"recipe\": {\n",
    "                     \"name\": get_title(downloaded),\n",
    "                     \"yield\": None,\n",
    "                     \"ingredients\": get_ingredients(df.text.to_list())\n",
    "                    }\n",
    "                }  \n",
    "            return recipe\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "def sentence_parser(result):\n",
    "    # getting all the paragraphs\n",
    "    text = []\n",
    "    try:\n",
    "        sentences = sent_tokenize(result, language='french')\n",
    "        for sentence in sentences:\n",
    "            if (sentence.replace(\"\\n\",\"* \").replace(\"– \",\"* \").replace(\"- \",\"* \").replace(\"• \",\"* \").replace(\"• \",\"* \").count('*') > 2):\n",
    "                [text.append(x) for x in sentence.replace(\"\\n\",\"* \").replace(\"– \",\"* \").replace(\"- \",\"* \").replace(\"• \",\"* \").replace(\"• \",\"* \").split(\"* \")]\n",
    "            else:\n",
    "                [text.append(x) for x in sentence.replace('\\n', '* ').replace('\\r', '* ').replace('\\xa0', '* ').split('* ')]\n",
    "\n",
    "        # remove empty strings from list\n",
    "        return list(filter(None, text))\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "\n",
    "def get_title(downloaded):\n",
    "    return trafilatura.bare_extraction(downloaded)['title']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8523d065",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
