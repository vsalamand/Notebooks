{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "511d554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining functions to scrape website & food blogs\n",
    "## 1. With application/ld+json\n",
    "## 2. With schema tags itemprop\n",
    "## 3. With unstructured format \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e9208b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_ld= [\n",
    "    \"https://www.marmiton.org/recettes/recette_gratin-dauphinois-tres-facile_58956.aspx\",\n",
    "    \"https://clemfoodie.com/2021/08/22/crumble-aux-prunes-rouges-et-amandes/\",\n",
    "    \"https://tangerinezest.com/pizza-tomate-burrata-basilic-et-mortadelle/\",\n",
    "    \"https://recettesdejulie.fr/10351/crumble-mirabelles-avoine-noisettes/\"\n",
    "]\n",
    "    \n",
    "microdata = [\n",
    "    \"https://mesbrouillonsdecuisine.fr/pancakes-sales-a-la-farine-de-pois-chiches-jeunes-pousses-depinards-et-tomates-sechees/\"\n",
    "]\n",
    "    \n",
    "hard_test_urls = [\n",
    "    \"https://www.undejeunerdesoleil.com/2018/05/tramezzini-thon-artichauts-venise.html\",\n",
    "    \"http://www.chezmisa.com/burgers-de-boeuf-persilles-et-sauce-au-miel/\",\n",
    "    \"https://cookingjulia.blogspot.com/2021/08/poulet-la-mexicaine.html\",\n",
    "    \"https://wernerhappyeats.com/djeunerdner/2017/12/29/grilled-chicken-lunch-bento-yxbn2\",\n",
    "    \"https://doriannn.blogspot.com/2021/08/knackinkorea-parce-que-decidement-je-ne.html\",\n",
    "    \"https://madamcadamia.com/2021/09/02/crumble-aux-mures-et-noisettes/\",\n",
    "    \"https://www.plusunemiettedanslassiette.fr/moules-marinara/\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "966b3d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import extruct\n",
    "import pprint\n",
    "from w3lib.html import get_base_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "23b09155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recipe': {'name': \"Knack'in'Korea parce que décidément je ne sais pas résister à une recette...\",\n",
       "  'yield': None,\n",
       "  'ingredients': ['200g de mini-knacks ',\n",
       "   '1 petit poivron rouge et 1 petit rouge ',\n",
       "   '1 oignon ',\n",
       "   \"à soupe d'huile de tournesol\",\n",
       "   'à soupe de ketchup - 1 cuil.',\n",
       "   'à soupe de sauce soja - ½ cuil.',\n",
       "   'à soupe de jocheong... ou de miel liquide - 1 ou 2 cuil.',\n",
       "   \"à café de gochujang (ou d'un autre truc qui pique)...\"]}}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe = scrape_recipe(hard_test_urls[4])\n",
    "recipe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0049518a",
   "metadata": {},
   "source": [
    "# Scrapping class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3a4785b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "saved_model_path = \"/Users/vincentsalamand/Documents/datascience/models/recipe_cat_spacy_model_150921_full\"\n",
    "nlp = spacy.load(saved_model_path)\n",
    "\n",
    "def scrape_recipe(url):\n",
    "    recipe = scrape_structured_data(url)\n",
    "    if recipe is None:\n",
    "        recipe = scrape_unstructured_data(url)\n",
    "    return recipe\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0114bc4",
   "metadata": {},
   "source": [
    "# 0. Ingredients filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4cd65fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ingredients(text_list):\n",
    "    docs = list(nlp.pipe(text_list))\n",
    "    predictions = []\n",
    "    for doc in docs:\n",
    "        if max(doc.cats, key=doc.cats.get) == \"ingredient\":\n",
    "            predictions.append(doc.text)\n",
    "    return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc30ed18",
   "metadata": {},
   "source": [
    "# 1. Scrapping JSON-LD OR MICRODATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "00e3c8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Fetch structured JSON-LD OR MICRODATA data from a given URL.\"\"\"\n",
    "from typing import Optional, List\n",
    "import requests\n",
    "import extruct\n",
    "from w3lib.html import get_base_url\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_structured_data(url: str) -> Optional[List[dict]]:\n",
    "    \"\"\"Parse structured data from a URL.\"\"\"\n",
    "    headers = {\n",
    "        'Access-Control-Allow-Origin': '*',\n",
    "        'Access-Control-Allow-Methods': 'GET',\n",
    "        'Access-Control-Allow-Headers': 'Content-Type',\n",
    "        'Access-Control-Max-Age': '3600',\n",
    "        'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0'\n",
    "    }    \n",
    "    req = requests.get(url, headers=headers)\n",
    "    base_url = get_base_url(req.content, url)\n",
    "    html = get_html(url) \n",
    "    metadata = get_metadata(html, url)\n",
    "    try:\n",
    "        if metadata:\n",
    "            recipe_df = get_recipe_df(metadata)\n",
    "            recipe = {\"recipe\": {\n",
    "                         \"name\": recipe_df.name.values[0],\n",
    "                         \"yield\": recipe_df.recipeYield.values[0],\n",
    "                         \"ingredients\": get_ingredients(recipe_df.recipeIngredient.values[0])\n",
    "                        }\n",
    "                    }            \n",
    "            return recipe\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_html(url: str):\n",
    "    \"\"\"Get raw HTML from a URL.\"\"\"\n",
    "    headers = {\n",
    "        'Access-Control-Allow-Origin': '*',\n",
    "        'Access-Control-Allow-Methods': 'GET',\n",
    "        'Access-Control-Allow-Headers': 'Content-Type',\n",
    "        'Access-Control-Max-Age': '3600',\n",
    "        'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0'\n",
    "    }\n",
    "    req = requests.get(url, headers=headers)\n",
    "    return req.text\n",
    "\n",
    "\n",
    "def get_metadata(html, url: str):\n",
    "    r = requests.get(url)\n",
    "    \"\"\"Fetch JSON-LD structured data.\"\"\"\n",
    "    metadata = extruct.extract(\n",
    "        html,\n",
    "        base_url = get_base_url(r.text, r.url),\n",
    "        syntaxes=['json-ld'],\n",
    "        uniform=True\n",
    "    )['json-ld']\n",
    "    \"\"\"If empty, try fetch Microdata structured data.\"\"\"    \n",
    "    if metadata == []:\n",
    "        metadata = extruct.extract(\n",
    "            html,\n",
    "            base_url = get_base_url(r.text, r.url),\n",
    "            syntaxes=['microdata'],\n",
    "            uniform=True\n",
    "        )['microdata']        \n",
    "    if bool(metadata) and isinstance(metadata, list):\n",
    "        metadata = metadata[0]\n",
    "    return metadata\n",
    "\n",
    "def get_recipe_df(metadata):\n",
    "    #check metadata dict format \n",
    "    if '@graph' in metadata:\n",
    "        recipe_df = pd.DataFrame(metadata['@graph'])\n",
    "    else:\n",
    "        recipe_df = pd.DataFrame.from_dict(metadata, orient='index').transpose()\n",
    "    #get first row with recipeIngredient\n",
    "    recipe_df = recipe_df.sort_values(by='recipeIngredient').head(1)\n",
    "    return recipe_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d2015a",
   "metadata": {},
   "source": [
    "# 2. Non-structured data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec54113e",
   "metadata": {},
   "source": [
    "## Using spaCy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "487c50fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "#import pandas as pd\n",
    "import spacy\n",
    "saved_model_path = \"/Users/vincentsalamand/Documents/datascience/models/recipe_cat_spacy_model_150921_full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5a1bafac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load nlp model\n",
    "nlp = spacy.load(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2f9d45e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ingredient': 0.0011802221415564418, 'instruction ': 0.05197196453809738, 'title': 0.0027056727558374405, 'other': 0.9441421627998352}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'other'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Le problème, c'est que je cherche souvent des recettes et que j'ai aussi souvent faim... Du coup en passant chez Sue, sur son blog plus que gourmand My Korean Kitchen et en tombant sur cette recette avec l'appétit au garde à vous, je me suis tout de suite imaginé me léchant les doigts... ce qui n'a pas tardé !\"\n",
    "demo = nlp(text)\n",
    "print(demo.cats)\n",
    "max(demo.cats, key=demo.cats.get)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ac74ef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trafilatura import fetch_url, extract\n",
    "import trafilatura\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "\n",
    "def scrape_unstructured_data(url: str):\n",
    "    downloaded = fetch_url(url)\n",
    "    # to get the main text of a page\n",
    "    if downloaded is not None:\n",
    "        result = extract(downloaded, include_comments=False)\n",
    "        text = sentence_parser(result)\n",
    "        if text is not None:\n",
    "            df = pd.DataFrame(text, columns=['text']).dropna()\n",
    "            recipe = {\"recipe\": {\n",
    "                     \"name\": get_title(downloaded),\n",
    "                     \"yield\": None,\n",
    "                     \"ingredients\": get_ingredients(df.text.to_list())\n",
    "                    }\n",
    "                }  \n",
    "            return recipe\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "def sentence_parser(result):\n",
    "    # getting all the paragraphs\n",
    "    text = []\n",
    "    try:\n",
    "        sentences = sent_tokenize(result, language='french')\n",
    "        for sentence in sentences:\n",
    "            if (sentence.replace(\"\\n\",\"* \").replace(\"– \",\"* \").replace(\"- \",\"* \").replace(\"• \",\"* \").replace(\"• \",\"* \").count('*') > 2):\n",
    "                [text.append(x) for x in sentence.replace(\"\\n\",\"* \").replace(\"– \",\"* \").replace(\"- \",\"* \").replace(\"• \",\"* \").replace(\"• \",\"* \").split(\"* \")]\n",
    "            else:\n",
    "                [text.append(x) for x in sentence.replace('\\n', '* ').replace('\\r', '* ').replace('\\xa0', '* ').split('* ')]\n",
    "\n",
    "        # remove empty strings from list\n",
    "        return list(filter(None, text))\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "\n",
    "def get_title(downloaded):\n",
    "    return trafilatura.bare_extraction(downloaded)['title']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b2fba4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recipe': {'name': 'Bento au Poulet Grillé — Werner Happy Eats',\n",
       "  'yield': None,\n",
       "  'ingredients': []}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = hard_test_urls[3]\n",
    "scrape_unstructured_data(url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "575c9649",
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_test_urls = [\n",
    "    \"https://www.undejeunerdesoleil.com/2018/05/tramezzini-thon-artichauts-venise.html\",\n",
    "    \"http://www.chezmisa.com/burgers-de-boeuf-persilles-et-sauce-au-miel/\",\n",
    "    \"https://cookingjulia.blogspot.com/2021/08/poulet-la-mexicaine.html\",\n",
    "    \"https://wernerhappyeats.com/djeunerdner/2017/12/29/grilled-chicken-lunch-bento-yxbn2\",\n",
    "    \"https://doriannn.blogspot.com/2021/08/knackinkorea-parce-que-decidement-je-ne.html\",\n",
    "    \"https://madamcadamia.com/2021/09/02/crumble-aux-mures-et-noisettes/\",\n",
    "    \"https://www.plusunemiettedanslassiette.fr/moules-marinara/\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b2b1ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
